# Define the deployment of Raft node as stateful set
# The cluster as a whole looks like a single service
# to the client
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: raft-node
  namespace: raft-k8s
  labels:
    app: raft
    raft-cluster-id: raft000
spec:
  selector:
    matchLabels:
      app: raft
      raft-cluster-id: raft000
    serviceName: "raft-node"
    replicas: 3
    
    # Define the pod template for the raft-node
    # its volumes, environment, ports and so on
    template:
      metadata:
        name: raft-node
        namespace: raft-k8s
        labels:
          app: raft
          tier: datastore
          raft-cluster-id: raft000
      
      # Now specify the port that makes up the
      # raft cluster.
      spec:
        containers:
        - name: raft-node
          image: su225/raft:0
          imagePullPolicy: Always
          # Specify the ports to be exposed in
          # the pod for communication with other nodes
          ports:
          - name: rpc
            containerPort: 6666
          - name: api
            containerPort: 7777
          
          # Specify the environment variables required
          # for the start of the container as well as
          # the cluster formation.
          env:
          # Turn on RUNNING_IN_K8S_ENV to pick the
          # kubernetes joiner for cluster formation
          - name: RUNNING_IN_K8S_ENV
            value: "true"

          # Specify the node ID of the given node
          - name: NODE_ID
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          
          # Specify the election timeout
          # TODO: Remove this
          - name: ELECTION_TIMEOUT_MILLIS
            value: "3000"
          
          # Host and port of the kubernetes discovery
          # provider service. Ideally this should not
          # be hardcoded and the name must be encoded
          - name: K8S_DISCOVERY_PROVIDER_URL
            value: "k8s-discovery-service:8888"

        # Specify the volumes to be mounted
        # to the container to store data
        volumeMounts:
        # Volume to keep write-ahead log entries
        # and the metadata associated with them
        - name: log
          mountPath: /node/cluster-data/log
    
        # Volume to persist raft state
        - name: state
          mountPath: /node/cluster-data/state
    
        # Volume to persist snapshot
        - name: snapshot
          mountPath: /node/cluster-data/snapshot
    
        # volume containing the labels on the pod
        - name: cluster
          mountPath: /node/cluster-data/cluster
          readOnly: true

        # Define the volumes - the actual storage for
        # the data and the downward API information like
        # pod labels, annotations, namespace and so on
        volumes:
        - name: cluster
          downwardAPI:
            items:
            # Write all the labels to a file "labels"
            # in the cluster directory
            - path: "labels"
              fieldRef:
                fieldPath: metadata.labels  
            
            # Write the current namespace to "k8s-ns"
            # in the cluster directory
            - path: "k8s-ns"
              fieldRef:
                fieldPath: metadata.namespace

    volumeClaimTemplates:
    # Volume claim template for storing write-ahead
    # log entries and associated metadata. Currently
    # this only works for DigitalOcean block storage
    # as specified by "do-block-storage". Ideally, this
    # should have been portable.
    - metadata:
        name: log
        namespace: raft-k8s
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: do-block-storage
        resources:
          requests:
            storage: 1Gi
    
    # Volume claim template for storing raft state
    # This does not require a lot of space. But 1Gi
    # looks like minimum space?
    - metadata:
        name: state
        namespace: raft-k8s
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: do-block-storage
        resources:
          storage: 1Gi
    
    # Volume claim template for storing snapshot data
    # This might require lot of space
    - metadata:
        name: snapshot
        namespace: raft-k8s
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: do-block-storage
        resources:
          storage: 5Gi
---
# Define the service for the raft cluster such that the
# entire cluster appears as a single unit and the distribution
# is completely transparent to the client.
apiVersion: v1
kind: Service
metadata:
  name: raft-svc
  namespace: raft-k8s
  labels:
    app: raft
    tier: datastore
    raft-cluster-id: raft000
    version: 0.1
spec:
  selector:
    app: raft
    raft-cluster-id: raft000
  ports:
  - protocol: TCP
    port: 7777